import torch
import torch.nn as nn

# note that this is specific to the gaussian prior
# we'd need to implement something slightly more generic - our LJ experiments use another prior for instance --> space restricted gaussian
def mc_chain(target_model,flow_net, nbsamples, mc_steps, odesteps = int(1e2)):
    """
    MCMC sampling routine associated to a trained flow net, with a divergence function

    Args:
        target_model: target model to sample from (must have a log_likelihood method)
        flow_net: flow net to use for the proposal distribution
        nbsamples: number of samples to generate
        mc_steps: number of MCMC steps to perform
        odesteps: number of ODE steps to perform for proposal

    Returns:
        final_samples: final samples generated by the MCMC routine (samples, batch, dim)
        logtargets: log likelihood of the final samples (samples, batch, 1)
        lognvps: log likelihood of the proposal distribution (samples, batch, 1)
        acceptance: acceptance rate of the MCMC routine
    """
    # first sample

    acceptance = 0

    # gaussian prior
    x0 = torch.randn(nbsamples, 2).to(device).detach()
    logbase0 = - reduce(x0 ** 2, 'b d -> b 1', 'sum') / 2 - np.log(2 * np.pi)

    ts, nvp_trajs, nvp_traces = flow_net.sample_traj_logprob( x0, n_steps=odesteps)
    xproposal = nvp_trajs[-1]
    lognvpproposal = logbase0 - nvp_traces[-1]

    final_samples = [xproposal]
    logtargets = [target_model.log_likelihood(xproposal.cpu()).to(device).unsqueeze(1)]
    lognvps = [lognvpproposal]

    for k in range(mc_steps):
        print(f'step {k+1}/{mc_steps}')

        prev_x = final_samples[-1].clone()
        lognvpprev = lognvps[-1].clone()
        logtargetprev = logtargets[-1].clone()

        # sample a random point
        x0 = torch.randn(nbsamples, 2).to(device).detach()
        logbase0 = - reduce(x0 ** 2, 'b d -> b 1', 'sum') / 2 - np.log(2 * np.pi)

        ts, nvp_trajs, nvp_traces = flow_net.sample_traj_logprob( x0, n_steps=odesteps)
        xproposal = nvp_trajs[-1]
        lognvpproposal = logbase0 - nvp_traces[-1]




        #logtargetproposal
        logtargetproposal = target_model.log_likelihood(xproposal.cpu()).to(device).unsqueeze(1)


        mc_ratio = logtargetproposal - logtargetprev + lognvpprev - lognvpproposal
        mc_ratio = torch.min(mc_ratio, torch.zeros_like(mc_ratio))
        print(mc_ratio)

        # accept or reject
        accept = (torch.log(torch.rand_like(mc_ratio)) <= mc_ratio).flatten()
        print(accept)
        acceptance += accept.sum().item()
        # update the samples
        prev_x[accept] = xproposal[accept]
        logtargetprev[accept] = logtargetproposal[accept]
        lognvpprev[accept] = lognvpproposal[accept]



        # append the samples
        final_samples.append(prev_x)
        logtargets.append(logtargetprev)
        lognvps.append(lognvpprev)

    return rearrange(final_samples, 's b d -> s b d'), rearrange(logtargets, 's b d -> s b d '), rearrange(lognvps, 's b d -> s b d '), acceptance / (nbsamples * mc_steps)

# modified version for our LJ experiments in 2d
def mc_chain_LJ(target_model,flow_net, nbsamples, mc_steps, odesteps = int(1e2), div_samples = int(1e3)):
    """
    MCMC sampling routine associated to a trained flow net, with a divergence function

    Args:
        target_model: target model to sample from (must have a log_likelihood method)
        flow_net: flow net to use for the proposal distribution
        nbsamples: number of samples to generate
        mc_steps: number of MCMC steps to perform
        odesteps: number of ODE steps to perform for proposal

    Returns:
        final_samples: final samples generated by the MCMC routine (samples, batch, dim)
        logtargets: log likelihood of the final samples (samples, batch, 1)
        lognvps: log likelihood of the proposal distribution (samples, batch, 1)
        acceptance: acceptance rate of the MCMC routine
    """
    # first sample
    nparticles = target_model.nparticles
    dim = target_model.dim
    base_sigma = 0.5 # used during training

    acceptance = 0

    # need to modyfy this to match the trainnig
    new_base = (torch.randn((nbsamples, nparticles, dim)).to(device)) * base_sigma
    new_base = new_base[torch.arange(new_base.size(0)).unsqueeze(-1), torch.argsort(new_base [:, :, 0], dim=1)] # sort by x
    x0 = new_base.detach()

    # the sorting will impact the proposal loglikelyhood There's a combinatoric factor in here
    logbase0 = - reduce(x0 ** 2, 'b p d -> b 1', 'sum') / (2 * base_sigma ** 2) - dim * nbparticles * np.log((2 * np.pi * base_sigma ** 2)) + np.log(math.factorial(nparticles))

    ts, nvp_trajs, nvp_traces = flow_net.sample_traj_logprob( x0, n_steps=odesteps, div_samples=div_samples)
    xproposal = nvp_trajs[-1]
    lognvpproposal = logbase0 - nvp_traces[-1]

    final_samples = [xproposal]
    logtargets = [target_model.log_likelihood(xproposal.cpu()).to(device).unsqueeze(1)]
    lognvps = [lognvpproposal]

    for k in range(mc_steps):
        print(f'step {k+1}/{mc_steps}')

        prev_x = final_samples[-1].clone()
        lognvpprev = lognvps[-1].clone()
        logtargetprev = logtargets[-1].clone()

        # sample a random point
        new_base = (torch.randn((nbsamples, nparticles, dim)).to(device)) * base_sigma
        new_base = new_base[torch.arange(new_base.size(0)).unsqueeze(-1), torch.argsort(new_base [:, :, 0], dim=1)] # sort by x
        x0 = new_base.detach()

        logbase0 = - reduce(x0 ** 2, 'b p d -> b 1', 'sum') / (2 * base_sigma ** 2) - dim * nbparticles * np.log((2 * np.pi * base_sigma ** 2)) + np.log(math.factorial(nparticles))

        ts, nvp_trajs, nvp_traces = flow_net.sample_traj_logprob( x0, n_steps=odesteps, div_samples=div_samples)
        xproposal = nvp_trajs[-1]
        lognvpproposal = logbase0 - nvp_traces[-1]




        #logtargetproposal
        logtargetproposal = target_model.log_likelihood(xproposal.cpu()).to(device).unsqueeze(1)


        mc_ratio = logtargetproposal - logtargetprev + lognvpprev - lognvpproposal
        mc_ratio = torch.min(mc_ratio, torch.zeros_like(mc_ratio))
        # print(mc_ratio)

        # accept or reject
        accept = (torch.log(torch.rand_like(mc_ratio)) <= mc_ratio).flatten()
        # print(accept)
        acceptance += accept.sum().item()
        # update the samples
        prev_x[accept] = xproposal[accept]
        logtargetprev[accept] = logtargetproposal[accept]
        lognvpprev[accept] = lognvpproposal[accept]



        # append the samples
        final_samples.append(prev_x)
        logtargets.append(logtargetprev)
        lognvps.append(lognvpprev)

    return rearrange(final_samples, 's b p d -> s b p d'), rearrange(logtargets, 's b d -> s b d '), rearrange(lognvps, 's b d -> s b d '), acceptance / (nbsamples * mc_steps)