/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'flow_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['flow_model'])`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:44: attribute 'flow_model' removed from hparams because it cannot be pickled
You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Missing logger folder: flow_model_learning_rate_0.0001_batch_size_256_nb_epochs_60_gnn_hidden_dim_32_tf_hidden_dim_256_temp_1.0_nb_layers_4_nn_egnn_var/lightning_logs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name       | Type          | Params
---------------------------------------------
0 | flow_model | EGNN_dynamics | 3.1 K 
---------------------------------------------
3.1 K     Trainable params
0         Non-trainable params
3.1 K     Total params
0.013     Total estimated model params size (MB)
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
[rank: 0] Received SIGTERM: 15
cuda
torch.Size([2, 1000000, 13, 3]) torch.Size([1000000, 13, 3])
Initializing custom EGNN_dynamics
Number of parameters in the model: 3150
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'flow_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['flow_model'])`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:44: attribute 'flow_model' removed from hparams because it cannot be pickled
You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /mnt/ssd/flow_matching/flash-div/0702_lj_13_reflow/flow_model_learning_rate_0.0001_batch_size_256_nb_epochs_60_gnn_hidden_dim_32_tf_hidden_dim_256_temp_1.0_nb_layers_4_nn_egnn_var/checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name       | Type          | Params
---------------------------------------------
0 | flow_model | EGNN_dynamics | 3.1 K 
---------------------------------------------
3.1 K     Trainable params
0         Non-trainable params
3.1 K     Total params
0.013     Total estimated model params size (MB)
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
[rank: 0] Received SIGTERM: 15
cuda
torch.Size([2, 1000000, 13, 3]) torch.Size([1000000, 13, 3])
Initializing custom EGNN_dynamics
Number of parameters in the model: 3150
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'flow_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['flow_model'])`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:44: attribute 'flow_model' removed from hparams because it cannot be pickled
You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /mnt/ssd/flow_matching/flash-div/0702_lj_13_reflow/flow_model_learning_rate_0.0001_batch_size_256_nb_epochs_60_gnn_hidden_dim_32_tf_hidden_dim_256_temp_1.0_nb_layers_4_nn_egnn_var/checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name       | Type          | Params
---------------------------------------------
0 | flow_model | EGNN_dynamics | 3.0 K 
---------------------------------------------
3.0 K     Trainable params
0         Non-trainable params
3.0 K     Total params
0.012     Total estimated model params size (MB)
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
[rank: 0] Received SIGTERM: 15
cuda
torch.Size([2, 1000000, 13, 3]) torch.Size([1000000, 13, 3])
Initializing custom EGNN_dynamics
Number of parameters in the model: 3018
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'flow_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['flow_model'])`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:44: attribute 'flow_model' removed from hparams because it cannot be pickled
You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /mnt/ssd/flow_matching/flash-div/0707_lj_13_reflow/flow_model_learning_rate_0.0001_batch_size_256_nb_epochs_60_gnn_hidden_dim_32_tf_hidden_dim_256_temp_1.0_nb_layers_4_nn_egnn_noe/checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name       | Type              | Params
-------------------------------------------------
0 | flow_model | EGNN_dynamics_Noe | 3.1 K 
-------------------------------------------------
3.1 K     Trainable params
0         Non-trainable params
3.1 K     Total params
0.012     Total estimated model params size (MB)
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'flow_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['flow_model'])`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:44: attribute 'flow_model' removed from hparams because it cannot be pickled
You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /mnt/ssd/flow_matching/flash-div/0707_lj_13_reflow/flow_model_learning_rate_0.0001_batch_size_256_nb_epochs_60_gnn_hidden_dim_32_tf_hidden_dim_256_temp_1.0_nb_layers_4_nn_egnn_noe/checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name       | Type              | Params
-------------------------------------------------
0 | flow_model | EGNN_dynamics_Noe | 3.1 K 
-------------------------------------------------
3.1 K     Trainable params
0         Non-trainable params
3.1 K     Total params
0.012     Total estimated model params size (MB)
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'flow_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['flow_model'])`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:44: attribute 'flow_model' removed from hparams because it cannot be pickled
You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /mnt/ssd/flow_matching/flash-div/0707_lj_13_reflow/flow_model_learning_rate_0.0001_batch_size_256_nb_epochs_60_gnn_hidden_dim_32_tf_hidden_dim_256_temp_1.0_nb_layers_4_nn_egnn_noe/checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name       | Type              | Params
-------------------------------------------------
0 | flow_model | EGNN_dynamics_Noe | 3.1 K 
-------------------------------------------------
3.1 K     Trainable params
0         Non-trainable params
3.1 K     Total params
0.012     Total estimated model params size (MB)
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
[rank: 0] Received SIGTERM: 15
cuda
torch.Size([2, 1000000, 13, 3]) torch.Size([1000000, 13, 3])
Initializing custom EGNN_dynamics
Number of parameters in the model: 3112
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'flow_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['flow_model'])`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:44: attribute 'flow_model' removed from hparams because it cannot be pickled
You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Missing logger folder: flow_model_learning_rate_0.0001_batch_size_256_nb_epochs_60_gnn_hidden_dim_32_tf_hidden_dim_256_temp_1.0_nb_layers_4_nn_egnn_var/lightning_logs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name       | Type          | Params
---------------------------------------------
0 | flow_model | EGNN_dynamics | 3.0 K 
---------------------------------------------
3.0 K     Trainable params
0         Non-trainable params
3.0 K     Total params
0.012     Total estimated model params size (MB)
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'flow_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['flow_model'])`.
[rank: 0] Received SIGTERM: 15
cuda
torch.Size([2, 1000000, 13, 3]) torch.Size([1000000, 13, 3])
Initializing custom EGNN_dynamics
Number of parameters in the model: 3112
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:199: Attribute 'flow_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['flow_model'])`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/utilities/parsing.py:44: attribute 'flow_model' removed from hparams because it cannot be pickled
You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /mnt/ssd/flow_matching/flash-div/0707_lj_13_reflow/flow_model_learning_rate_0.0001_batch_size_256_nb_epochs_60_gnn_hidden_dim_32_tf_hidden_dim_256_temp_1.0_nb_layers_4_nn_egnn_var/checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name       | Type          | Params
---------------------------------------------
0 | flow_model | EGNN_dynamics | 3.0 K 
---------------------------------------------
3.0 K     Trainable params
0         Non-trainable params
3.0 K     Total params
0.012     Total estimated model params size (MB)
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
/home/sherryli/xsli/softwares/anaconda3/envs/lightning/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.
